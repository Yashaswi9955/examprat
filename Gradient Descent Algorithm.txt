import numpy as np
import matplotlib.pyplot as plt

def mean_squared_error(y_true, y_predicted):
	cost = np.sum((y_true-y_predicted)**2) / len(y_true) #Calculating the loss or cost
	return cost
def gradient_descent(x, y, iterations = 1000, learning_rate = 0.0001, stopping_threshold =
	#Initializing weight, bias, learning rate and iterations
	current_weight = 0.1
	current_bias = 0.01
	iterations = iterations
	learning_rate = learning_rate
	n = float(len(x))
	costs = []
	weights = []
	previous_cost = None
	for i in range(iterations): #Estimation of optimal parameters
		y_predicted = (current_weight * x) + current_bias #Making predictions
		current_cost = mean_squared_error(y, y_predicted) #Calculationg the current cost
		#If the change in cost is less than or equal to stopping_threshold we stop the gra
		if previous_cost and abs(previous_cost-current_cost)<=stopping_threshold:
			break
		previous_cost = current_cost
		costs.append(current_cost)
		weights.append(current_weight)
		#Calculating the gradients
		weight_derivative = -(2/n) * sum(x * (y-y_predicted))
		bias_derivative = -(2/n) * sum(y-y_predicted)
		#Updating weights and bias
		current_weight = current_weight - (learning_rate * weight_derivative)
		current_bias = current_bias - (learning_rate * bias_derivative)
		#Printing the parameters for each 1000th iteration
		print(f"Iteration{i+1}:Cost{current_cost},Weight\{current_weight},Bias{current_bia
	#Visualizing the weights and cost at for all iterations
	plt.figure(figsize = (8,6))
	plt.plot(weights, costs)
	plt.scatter(weights, costs, marker='o', color='red')
	plt.title("Cost vs Weights")
	plt.ylabel("Cost")
	plt.xlabel("Weight")
	plt.show()
	return current_weight, current_bias
#Estimating weight and bias using gradient descent
estimated_weight, eatimated_bias = gradient_descent(X, Y, iterations=2000)
print(f"Estimated Weight: {estimated_weight}\nEstimated Bias: {eatimated_bias}")
Y_pred = estimated_weight*X + eatimated_bias #Making predictions using estimated parameter
#Plotting the regression line
plt.figure(figsize = (8,6))
plt.scatter(X, Y, marker='o', color='red')
plt.plot([min(X), max(X)], [min(Y_pred), max(Y_pred)], color='blue',markerfacecolor='red',
plt.xlabel("X")
plt.ylabel("Y")
plt.show()


